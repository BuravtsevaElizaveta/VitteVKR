# components/plate_assistant.py
# –ù–æ–º–µ—Ä + –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç:
# - –î–µ—Ç–µ–∫—Ü–∏—è –ø–ª–∞—Å—Ç–∏–Ω—ã: YOLO (–±–µ–∑ —Ä–µ—Å–∞–π–∑–∞) ‚Üí Haar (–±–µ–∑ —Ä–µ—Å–∞–π–∑–∞) ‚Üí –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ª–æ–∫–∞—Ç–æ—Ä (fallback).
# - –ï—Å–ª–∏ TensorFlow –¥–æ—Å—Ç—É–ø–µ–Ω: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–æ–≤ + CNN (model.h5).
# - –ï—Å–ª–∏ TensorFlow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ª—ë–≥–∫—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é + LLM-–≤–∏–∑–∏–æ–Ω.
# - –°—Ç—Ä–æ–∫–∞ –Ω–æ–º–µ—Ä–∞ –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤—Å–µ–≥–¥–∞ (–¥–∞–∂–µ –µ—Å–ª–∏ —Å–∏–º–≤–æ–ª—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –∫–∞–∫ '?').

from __future__ import annotations
from pathlib import Path
from typing import Tuple, List, Optional
import re, json, base64, time, logging
import numpy as np
import pandas as pd
import streamlit as st
import cv2
from PIL import Image

# ‚îÄ‚îÄ TensorFlow: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
TF_OK = True
TF_ERR = None
try:
    import tensorflow as tf  # –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±–ª–∞–∫–µ (Py 3.13)
except Exception as _e:
    TF_OK = False
    TF_ERR = _e

from utils.db import insert_detection
from openai_config import get_client, get_defaults

# ‚îÄ‚îÄ YOLO (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from ultralytics import YOLO
    _YOLO_OK = True
except Exception:
    _YOLO_OK = False

log = logging.getLogger(__name__)

# –ê–ª—Ñ–∞–≤–∏—Ç –º–æ–¥–µ–ª–∏ (legacy CNN)
_CHARS = '0123456789–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•'
_NUM2CHAR = {i: ch for i, ch in enumerate(_CHARS)}

# ‚îÄ‚îÄ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–∞ –±–µ–∑ TF (–ª–∞—Ç–∏–Ω–∏—Ü–∞‚Üî–∫–∏—Ä–∏–ª–ª–∏—Ü–∞, —Ñ–∏–ª—å—Ç—Ä—ã)
_MAP = str.maketrans({
    "O": "0", "o": "0", "I": "1", "l": "1",
    "–ê": "A", "–í": "B", "–ï": "E", "–ö": "K", "–ú": "M",
    "–ù": "H", "–û": "O", "–†": "P", "–°": "C", "–¢": "T", "–•": "X"
})
PLATE_RE = re.compile(r"[A-Z–ê-–Ø0-9]{5,10}")

def normalize_plate_text(text: str) -> str:
    if not text:
        return ""
    t = text.strip().upper().translate(_MAP)
    m = PLATE_RE.findall(t)
    return m[0] if m else t

# ‚îÄ‚îÄ ProxyAPI helpers
def _extract_text(resp) -> str:
    try:
        if hasattr(resp, "output_text") and resp.output_text:
            return resp.output_text.strip()
        if hasattr(resp, "output"):
            parts = []
            for itm in resp.output:
                if getattr(itm, "type", None) == "message":
                    for c in getattr(itm, "content", []):
                        t = getattr(c, "text", None)
                        if t:
                            parts.append(t)
            if parts:
                return " ".join(parts).strip()
    except Exception:
        pass
    return ""

def _img_to_b64(img_bgr: np.ndarray, max_side: int = 224, q: int = 35) -> str:
    h, w = img_bgr.shape[:2]
    s = max_side / float(max(h, w))
    if s < 1.0:
        img_bgr = cv2.resize(img_bgr, (int(w*s), int(h*s)), interpolation=cv2.INTER_AREA)
    ok, enc = cv2.imencode(".jpg", img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), int(q)])
    return base64.b64encode(enc).decode() if ok else ""

def _gpt_vision(client, sys_prompt: str, user_text: str, img_bgr: Optional[np.ndarray], model: str) -> str:
    content = [{"type": "input_text", "text": user_text}]
    if img_bgr is not None:
        content.append({"type": "input_image", "image_url": "data:image/jpeg;base64," + _img_to_b64(img_bgr)})
    try:
        r = client.responses.create(
            model=model,
            input=[{"role": "system", "content": sys_prompt},
                   {"role": "user", "content": content}],
            temperature=0.0, max_output_tokens=200
        )
        return _extract_text(r)
    except Exception as e:
        log.warning("Proxy error: %s", e)
        return ""

def gpt_brand(img, c, m): return _gpt_vision(c, "–û–ø—Ä–µ–¥–µ–ª–∏ –º–∞—Ä–∫—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –º–∞—Ä–∫—É.", "–ö–∞–∫–∞—è –º–∞—Ä–∫–∞ –∞–≤—Ç–æ?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–∞—Ä–∫—É"
def gpt_color(img, c, m): return _gpt_vision(c, "–û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–≤–µ—Ç –∫—É–∑–æ–≤–∞ (–æ–¥–Ω–æ —Å–ª–æ–≤–æ –ø–æ-—Ä—É—Å—Å–∫–∏).", "–ö–∞–∫–æ–π —Ü–≤–µ—Ç –∞–≤—Ç–æ?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ü–≤–µ—Ç"
def gpt_type (img, c, m): return _gpt_vision(c, "–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Ç–∏–ø: –ª–µ–≥–∫–æ–≤–æ–π/–≥—Ä—É–∑–æ–≤–æ–π/–∞–≤—Ç–æ–±—É—Å/–º–æ—Ç–æ—Ü–∏–∫–ª. –í–µ—Ä–Ω–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ.", "–ö–∞–∫–æ–π —Ç–∏–ø –¢–°?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–∏–ø –∞–≤—Ç–æ–º–æ–±–∏–ª—è"

def gpt_plate(img, c, m) -> str:
    # –ß—Ç–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∫–∞–∫ —Ç–µ–∫—Å—Ç–∞: –∫–æ—Ä–æ—Ç–∫–æ –∏ —Å—Ç—Ä–æ–≥–æ
    sys = ("–¢—ã —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—à—å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–æ–º–µ—Ä –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–æ–º–µ—Ä –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. "
           "–î–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç: –ê123–í–°77/–ê123–í–°777 (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞) –∏–ª–∏ –∞–Ω–∞–ª–æ–≥ –ª–∞—Ç–∏–Ω–∏—Ü–µ–π.")
    txt = _gpt_vision(c, sys, "–°—á–∏—Ç–∞–π –Ω–æ–º–µ—Ä –∏ –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –µ–≥–æ.", img, m)
    return normalize_plate_text(txt)

def gpt_reg_year(plate, c, m):
    if not plate:
        return "", ""
    sys = ("–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –≥–æ—Å–Ω–æ–º–µ—Ä (–ê123–í–°77/–ê123–í–°777). "
           "–ü–æ –∫–æ–¥—É —Ä–µ–≥–∏–æ–Ω–∞ –Ω–∞–∑–æ–≤–∏ —Å—É–±—ä–µ–∫—Ç –†–§ –∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏ –≥–æ–¥ –≤—ã–¥–∞—á–∏. "
           "–°—Ç—Ä–æ–≥–æ JSON: {\"region_name\":\"...\",\"year_issued\":\"...\"}.")
    txt = _gpt_vision(c, sys, f"–û–ø—Ä–µ–¥–µ–ª–∏ —Ä–µ–≥–∏–æ–Ω+–≥–æ–¥ –≤—ã–¥–∞—á–∏ –¥–ª—è: {plate}", None, m)
    try:
        j = json.loads(txt); return j.get("region_name", ""), j.get("year_issued", "")
    except Exception:
        return "", ""

# ‚îÄ‚îÄ –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
def _first_existing(paths: List[Path]) -> Optional[Path]:
    for p in paths:
        if p and Path(p).exists():
            return Path(p)
    return None

def _find_yolo(user: Optional[Path]) -> Optional[Path]:
    return _first_existing([user or Path(), Path("models/YOLOv8.pt"), Path("utils/YOLOv8.pt"), Path("YOLOv8.pt")])

def _find_cascade(user: Optional[Path]) -> Optional[Path]:
    return _first_existing([
        user or Path(),
        Path("haarcascade_licence_plate_rus_16stages.xml"),
        Path("haarcascade_russian_plate_number.xml"),
        Path("models/cascades/haarcascade_licence_plate_rus_16stages.xml"),
        Path("models/haarcascade_licence_plate_rus_16stages.xml"),
    ])

# ‚îÄ‚îÄ –ö—ç—à –º–æ–¥–µ–ª–µ–π
@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ CNN‚Ä¶")
def _load_cnn(path: Path):
    if not TF_OK:
        return None
    return tf.keras.models.load_model(str(path))

@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ YOLO‚Ä¶")
def _load_yolo(path: Path):
    if not _YOLO_OK:
        return None
    try:
        return YOLO(str(path))
    except Exception as e:
        log.error("YOLO load failed: %s", e)
        return None

# ‚îÄ‚îÄ –ì–µ–æ–º–µ—Ç—Ä–∏—è –æ–∫–Ω–∞
def _is_plausible_box(x, y, w, h, H, W) -> bool:
    if w <= 0 or h <= 0: return False
    ar = w / float(h)
    h_frac, w_frac = h/float(H), w/float(W)
    # –≥–æ—Å–Ω–æ–º–µ—Ä: —à–∏—Ä–æ–∫–∏–π (2.2‚Äì6.8), –ø–æ –≤—ã—Å–æ—Ç–µ 3‚Äì20% –∫–∞–¥—Ä–∞, –ø–æ —à–∏—Ä–∏–Ω–µ 8‚Äì60%
    if not (2.2 <= ar <= 6.8): return False
    if not (0.03 <= h_frac <= 0.20): return False
    if not (0.08 <= w_frac <= 0.60): return False
    return True

def _edge_density(gray_roi: np.ndarray) -> float:
    e = cv2.Canny(gray_roi, 70, 160)
    return float(e.mean()) / 255.0

# ‚îÄ‚îÄ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ª–æ–∫–∞—Ç–æ—Ä (fallback/—É—Ç–æ—á–Ω–µ–Ω–∏–µ)
def _locate_plate_morph(img_bgr: np.ndarray) -> Optional[Tuple[int,int,int,int]]:
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    rect_k = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rect_k)
    grad = cv2.Sobel(blackhat, cv2.CV_32F, 1, 0, ksize=-1)
    grad = np.absolute(grad)
    grad = (255 * (grad - grad.min()) / (grad.ptp() + 1e-6)).astype(np.uint8)
    grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, rect_k, iterations=1)
    _, bw = cv2.threshold(grad, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, rect_k, iterations=2)
    bw = cv2.medianBlur(bw, 3)

    cnts, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    H, W = gray.shape[:2]
    best = None; best_score = -1.0
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if not _is_plausible_box(x, y, w, h, H, W):
            continue
        roi = gray[y:y+h, x:x+w]
        score = 0.6 * _edge_density(roi) + 0.4 * (1.0 - min(1.0, abs((w/h) - 4.5) / 3.5))
        if score > best_score:
            best_score = score; best = (x, y, w, h)
    return best

# ‚îÄ‚îÄ Haar: –±–µ–∑ —Ä–µ—Å–∞–π–∑–∞ + —Å—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
def plate_detect_haar(img_bgr: np.ndarray, cascade_path: Path) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)

    cascade = cv2.CascadeClassifier(str(cascade_path))
    if cascade.empty():
        st.warning("–ö–∞—Å–∫–∞–¥ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ *.xml.")
        return img_bgr, None

    rects = cascade.detectMultiScale(gray, scaleFactor=1.08, minNeighbors=4,
                                     minSize=(50, 16), flags=cv2.CASCADE_SCALE_IMAGE)
    H, W = gray.shape[:2]
    best = None; best_score = -1.0
    for (x, y, w, h) in rects:
        if not _is_plausible_box(x, y, w, h, H, W):
            continue
        roi = gray[y:y+h, x:x+w]
        score = 0.6 * _edge_density(roi) + 0.4 * (1.0 - min(1.0, abs((w/h) - 4.5) / 3.5))
        if score > best_score:
            best_score = score; best = (x, y, w, h)

    if best is None:
        best = _locate_plate_morph(img_bgr)
        if best is None:
            return img_bgr, None

    x, y, w, h = best
    pad_x, pad_y = int(0.03*w), int(0.12*h)
    x1, y1 = max(0, x - pad_x), max(0, y - pad_y)
    x2, y2 = min(W, x + w + pad_x), min(H, y + h + pad_y)

    roi = img_bgr[y1:y2, x1:x2].copy()
    out = img_bgr.copy()
    cv2.rectangle(out, (x1, y1), (x2, y2), (0, 255, 0), 2)
    return out, roi

# ‚îÄ‚îÄ YOLO: –±–µ–∑ —Ä–µ—Å–∞–π–∑–∞ –≤—Ö–æ–¥–∞
def plate_detect_yolo(img_bgr: np.ndarray, model) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    res = model.predict(img_bgr, verbose=False, device="cpu", conf=0.25, iou=0.5)
    H, W = img_bgr.shape[:2]
    for r in res:
        names = getattr(r, "names", {}) or {}
        boxes = r.boxes
        if boxes is None or len(boxes) == 0:
            continue
        xyxy = boxes.xyxy.cpu().numpy().astype(int)
        conf = boxes.conf.cpu().numpy()
        cls  = boxes.cls.cpu().numpy().astype(int)
        cand = [i for i, c in enumerate(cls) if str(names.get(int(c), "")).lower().replace("-", "_") in ("license_plate", "licenseplate", "plate")]
        if not cand:
            ar = (xyxy[:, 2] - xyxy[:, 0]) / np.maximum(1, (xyxy[:, 3] - xyxy[:, 1]))
            scores = conf + (np.clip(1.0 - np.abs(ar - 4.5) / 3.5, 0, 1) * 0.5)
            idx = int(np.argmax(scores))
        else:
            idx = int(cand[np.argmax(conf[cand])])

        x1, y1, x2, y2 = xyxy[idx]
        w, h = x2 - x1, y2 - y1
        if not _is_plausible_box(x1, y1, w, h, H, W):
            best = _locate_plate_morph(img_bgr)
            if best is not None:
                x, y, w, h = best
                x1, y1, x2, y2 = x, y, x + w, y + h

        pad_x, pad_y = int(0.03*(x2-x1)), int(0.12*(y2-y1))
        x1, y1 = max(0, x1 - pad_x), max(0, y1 - pad_y)
        x2, y2 = min(W, x2 + pad_x), min(H, y2 + pad_y)

        roi = img_bgr[y1:y2, x1:x2].copy()
        out = img_bgr.copy()
        cv2.rectangle(out, (x1, y1), (x2, y2), (0, 255, 0), 2)
        return out, roi
    return img_bgr, None

def plate_detect(img_bgr: np.ndarray, method: str, yolo_path: Optional[Path], cascade_path: Optional[Path]) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    if method == "YOLOv8":
        ypath = _find_yolo(yolo_path)
        if ypath:
            y = _load_yolo(ypath)
            if y is not None:
                out, roi = plate_detect_yolo(img_bgr, y)
                if roi is not None:
                    return out, roi
    cpath = _find_cascade(cascade_path)
    if cpath:
        return plate_detect_haar(img_bgr, cpath)
    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –∫–∞—Å–∫–∞–¥–∞ –¥–ª—è Haar-–¥–µ—Ç–µ–∫—Ü–∏–∏.")
    return img_bgr, None

# ‚îÄ‚îÄ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–æ–≤ (legacy pipeline –¥–ª—è CNN)
def _segment_characters_legacy(image: np.ndarray) -> np.ndarray:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ 2D-–ø–∞—Ç—á–µ–π (–∫–∞–∂–¥—ã–π 44x24, –±–µ–ª—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ —á—ë—Ä–Ω–æ–º —Ñ–æ–Ω–µ),
    –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ. –≠—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç–æ—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å model.h5.
    """
    if image is None:
        return np.array([])

    img_lp = cv2.resize(image, (333, 75))  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ —Ç–∞–±–ª–∏—á–∫–∏
    img_gray = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)

    # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (—Ñ–æ–Ω –±–µ–ª—ã–π, —Å–∏–º–≤–æ–ª—ã —á—ë—Ä–Ω—ã–µ)
    img_bin = cv2.adaptiveThreshold(
        img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY, 11, 2
    )
    # –°–∫–ª–µ–∏–≤–∞–µ–º —Ä–∞–∑—Ä—ã–≤—ã
    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)))

    # –ß–∏—Å—Ç–∏–º –∫—Ä–∞—è
    img_bin[0:3, :], img_bin[:, 0:3] = 255, 255
    img_bin[72:75, :], img_bin[:, 330:333] = 255, 255

    LP_W, LP_H = img_bin.shape
    dims = [LP_W / 6, LP_W / 2, LP_H / 10, 2 * LP_H / 3]
    lower_h, upper_h = dims[0] * 0.5, dims[1] * 1.2
    lower_w, upper_w = dims[2] * 0.5, dims[3] * 1.2

    contours, hierarchy = cv2.findContours(img_bin.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if hierarchy is None:
        return np.array([])

    chars, xs = [], []
    for i, cnt in enumerate(contours):
        if hierarchy[0][i][3] == -1:
            continue  # –≤–Ω–µ—à–Ω–∏–π –∫–æ–Ω—Ç—É—Ä
        x, y, w, h = cv2.boundingRect(cnt)
        ar = w / float(h)
        if lower_h < h < upper_h and lower_w < w < upper_w and 0.3 < ar < 1.2:
            # –ò–Ω–≤–µ—Ä—Å–∏—è —Å–∏–º–≤–æ–ª–∞ ‚Üí –±–µ–ª—ã–π —Å–∏–º–≤–æ–ª –Ω–∞ —á—ë—Ä–Ω–æ–º (–∫–∞–∫ –∂–¥—ë—Ç CNN)
            char = cv2.subtract(255, cv2.resize(img_bin[y:y+h, x:x+w], (20, 40)))
            # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ 44x24
            char_copy = np.zeros((44, 24), dtype=np.uint8)
            char_copy[2:42, 2:22] = char
            chars.append(char_copy)
            xs.append(x)

    if not chars:
        return np.array([])

    idx_sorted = np.argsort(np.array(xs))
    return np.array([chars[i] for i in idx_sorted])

def _fix_dim(img):
    return np.stack((img,)*3, axis=-1) if img.ndim == 2 else img

def recognize_number_cnn(roi: np.ndarray, model, thr: float) -> Tuple[str, List[float]]:
    if model is None:
        return "", []
    seg_chars = _segment_characters_legacy(roi)
    if seg_chars.size == 0:
        return "", []
    out, confs = [], []
    for ch in seg_chars:
        img28 = cv2.resize(ch, (28, 28))
        X = _fix_dim(img28) / 255.0
        pr = model.predict(X.reshape(1, 28, 28, 3), verbose=0)
        idx = int(np.argmax(pr))
        cf = float(pr[0, idx])
        out.append(_NUM2CHAR[idx] if cf >= thr else "?")
        confs.append(cf)
    return "".join(out), confs

def fix_number_format_new_rus(s: str, confs: List[float]) -> Tuple[str, List[float]]:
    pat = r"^([–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•])\d{3}[–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•]{2}\d{2,3}$"
    if re.match(pat, s or ""): return s, confs
    if s and s[-1] in _CHARS:
        cand = s[:-1]
        if re.match(pat, cand or ""): return cand, confs[:-1]
    return s or "", confs

# ‚îÄ‚îÄ UI
def render_plate_assistant(db_path: Path):
    st.header("ü™™ –ù–æ–º–µ—Ä + –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç")

    defaults = get_defaults()
    with st.sidebar:
        st.subheader("ProxyAPI")
        api_key = st.text_input("API key", value=defaults["api_key"], type="password")
        base_url = st.text_input("Base URL", value=defaults["base_url"])
        gpt_model = st.selectbox("–ú–æ–¥–µ–ª—å", ["gpt-4o-mini","gpt-4o","gpt-4o-mini-compact"], index=0)

        st.subheader("–ú–æ–¥–µ–ª–∏")
        yolo_path_ui = st.text_input("YOLOv8 –≤–µ—Å–∞ (–∏—â–µ–º —Ç–∞–∫–∂–µ utils/YOLOv8.pt)", value="models/YOLOv8.pt")
        cascade_path_ui = st.text_input("Haar Cascade (–∞–≤—Ç–æ–ø–æ–∏—Å–∫)", value="haarcascade_licence_plate_rus_16stages.xml")
        cnn_path = st.text_input("CNN (model.h5)", value="model.h5")

        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
        fmt = st.selectbox("–§–æ—Ä–º–∞—Ç –Ω–æ–º–µ—Ä–∞", ['–°—Ç–∞—Ä—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ó–∞—Ä—É–±–µ–∂–Ω—ã–µ –Ω–æ–º–µ—Ä–∞'], index=1)
        det_m = st.selectbox("–ú–µ—Ç–æ–¥ –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä–∞", ['YOLOv8','Haar Cascade (legacy)'],
                             index=0 if (_find_yolo(Path(yolo_path_ui)) is not None and _YOLO_OK) else 1)
        thr = st.slider("–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (CNN), –Ω–∏–∂–µ ‚Äî '?'", 0.0, 1.0, 0.50, 0.05)

    if not TF_OK:
        st.info("TensorFlow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–º –¥–µ–ø–ª–æ–µ (Py 3.13). –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback: –ª—ë–≥–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è + LLM-–≤–∏–∑–∏–æ–Ω.")
        with st.expander("–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–µ—Ç–∞–ª—å"):
            st.code(repr(TF_ERR))

    c1, c2 = st.columns([1, 1])
    with c1:
        f = st.file_uploader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è", type=["jpg","jpeg","png"])
    with c2:
        do_all = st.checkbox("–í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å—ë (–º–∞—Ä–∫–∞/—Ç–∏–ø/—Ü–≤–µ—Ç/—Ä–µ–≥–∏–æ–Ω)", value=True)
        btn = st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", type="primary", use_container_width=True)

    if f:
        pil = Image.open(f)
        w = 420
        st.image(pil.resize((w, int(pil.height*(w/pil.width))), Image.Resampling.LANCZOS),
                 caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—É–º–µ–Ω—å—à–µ–Ω–æ)", width=420)

    if not btn or not f:
        return

    # –ì–æ—Ç–æ–≤–∏–º –∫–ª–∏–µ–Ω—Ç–∞ LLM –∑–∞—Ä–∞–Ω–µ–µ (–Ω—É–∂–µ–Ω –∏ –¥–ª—è TF-fallback)
    client = get_client(api_key=api_key, base_url=base_url)
    img_bgr = np.array(Image.open(f).convert("RGB"))[:, :, ::-1]  # –ø–æ–ª–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ

    # 1) –î–µ—Ç–µ–∫—Ü–∏—è –ø–ª–∞—Å—Ç–∏–Ω—ã
    det_img, roi = plate_detect(img_bgr, det_m, Path(yolo_path_ui), Path(cascade_path_ui))
    if roi is None:
        best = _locate_plate_morph(img_bgr)
        if best is not None:
            x,y,w,h = best
            pad_x, pad_y = int(0.03*w), int(0.12*h)
            x1,y1 = max(0, x - pad_x), max(0, y - pad_y)
            x2,y2 = min(img_bgr.shape[1], x+w+pad_x), min(img_bgr.shape[0], y+h+pad_y)
            roi = img_bgr[y1:y2, x1:x2].copy()
            det_img = img_bgr.copy()
            cv2.rectangle(det_img, (x1,y1), (x2,y2), (0,255,0), 2)

    st.subheader("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞‚Ä¶")
    st.image(cv2.cvtColor(det_img, cv2.COLOR_BGR2RGB), caption="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–æ–º–µ—Ä", width=360)

    # 2) –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: CNN (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) ‚Üí –∏–Ω–∞—á–µ LLM-–≤–∏–∑–∏–æ–Ω
    plate, confs = "", []
    if TF_OK:
        try:
            cnn = _load_cnn(Path(cnn_path))
        except Exception as e:
            cnn = None
            st.warning(f"CNN –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM-fallback: {e}")
        plate, confs = recognize_number_cnn(roi, cnn, thr) if cnn is not None else ("", [])
    if not plate:
        # fallback: LLM —á–∏—Ç–∞–µ—Ç –Ω–æ–º–µ—Ä –∫–∞–∫ —Ç–µ–∫—Å—Ç
        plate = gpt_plate(roi if roi is not None else img_bgr, client, gpt_model)
        confs = []  # —É LLM –Ω–µ—Ç –ø–æ–∫–∞–¥—Ä–æ–≤—ã—Ö —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    if fmt == '–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞' and plate:
        plate, confs = fix_number_format_new_rus(plate, confs)

    # 3) –î–æ–ø. –∞—Ç—Ä–∏–±—É—Ç—ã —á–µ—Ä–µ–∑ LLM (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
    brand = color = car_type = ""
    if do_all:
        brand = gpt_brand(img_bgr, client, gpt_model)
        color = gpt_color(img_bgr, client, gpt_model)
        car_type = gpt_type(img_bgr, client, gpt_model)
    region, year = ("","")
    if plate and fmt in ('–°—Ç–∞—Ä—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞'):
        st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–º–µ—Ä–∞ (—Ä–µ–≥–∏–æ–Ω, –≥–æ–¥ –≤—ã–¥–∞—á–∏)‚Ä¶")
        region, year = gpt_reg_year(plate, client, gpt_model)

    # 4) –í—ã–≤–æ–¥ (–Ω–æ–º–µ—Ä –≤—ã–≤–æ–¥–∏–º –í–°–ï–ì–î–ê)
    st.success("–ì–æ—Ç–æ–≤–æ.")
    st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    st.write(f"**–ù–æ–º–µ—Ä**: {plate or '‚Äî'}")
    if region: st.write(f"**–†–µ–≥–∏–æ–Ω**: {region}")
    if year:   st.write(f"**–ì–æ–¥ –≤—ã–¥–∞—á–∏**: {year}")
    if confs:
        avg = float(sum(confs)/len(confs))
        st.write(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (CNN): {avg:.2f}")
        if plate and len(plate) == len(confs):
            df = pd.DataFrame({"–°–∏–º–≤–æ–ª": list(plate), "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": confs})
            st.bar_chart(df, x="–°–∏–º–≤–æ–ª", y="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    if brand:    st.write(f"**–ú–∞—Ä–∫–∞**: {brand}")
    if car_type: st.write(f"**–¢–∏–ø**: {car_type}")
    if color:    st.write(f"**–¶–≤–µ—Ç**: {color}")

    # 5) –ë–î
    avg_conf = float(sum(confs)/len(confs)) if confs else None
    insert_detection(
        db_path=db_path,
        ts=time.strftime("%Y-%m-%dT%H:%M:%S"),
        kind="plate", source="image", filename=f.name,
        model=("YOLOv8‚Üí" if det_m=="YOLOv8" else "") + ("Haar/Morph+CNN" if TF_OK else "Haar/Morph+LLM"),
        label_en=plate or None, label_ru=plate or None, score=avg_conf,
        json_top5=None, price_min=None, price_max=None, currency=None, image_path=None,
        plate_number=plate or None, region=region or None, year_issued=year or None,
        brand=brand or None, car_type=car_type or None, color=color or None, conf_avg=avg_conf, extra_json=None
    )
    st.toast("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ detections.db", icon="üíæ")
