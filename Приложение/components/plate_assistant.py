# components/plate_assistant.py
# –ù–æ–º–µ—Ä + –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (YOLO/Haar/Morph + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π CNN + GPT)
from __future__ import annotations
from pathlib import Path
from typing import Tuple, List, Optional
import re, json, base64, time, logging
import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image

# --- –ª–æ–∫–∞–ª—å–Ω—ã–π utils —Ä–∞–Ω—å—à–µ –≤–Ω–µ—à–Ω–∏—Ö ---
import sys
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

# –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–º–ø–æ—Ä—Ç cv2
CV2_OK = True
CV2_ERR = None
try:
    import cv2  # type: ignore
except Exception as e:
    CV2_OK = False
    CV2_ERR = e

# –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–º–ø–æ—Ä—Ç TensorFlow (–Ω–∞ Cloud Py3.13 –µ–≥–æ –Ω–µ—Ç)
TF_OK = True
TF_ERR = None
try:
    import tensorflow as tf  # type: ignore
except Exception as e:
    TF_OK = False
    TF_ERR = e

from utils.db import insert_detection
from openai_config import get_client, get_defaults

# YOLO (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from ultralytics import YOLO  # type: ignore
    _YOLO_OK = True
except Exception:
    _YOLO_OK = False

log = logging.getLogger(__name__)

_CHARS = '0123456789–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•'
_NUM2CHAR = {i: ch for i, ch in enumerate(_CHARS)}

def _extract_text(resp) -> str:
    try:
        if hasattr(resp, "output_text") and resp.output_text:
            return resp.output_text.strip()
        if hasattr(resp, "output"):
            parts = []
            for itm in resp.output:
                if getattr(itm, "type", None) == "message":
                    for c in getattr(itm, "content", []):
                        t = getattr(c, "text", None)
                        if t: parts.append(t)
            if parts:
                return " ".join(parts).strip()
    except Exception:
        pass
    return ""

def _img_to_b64(img_bgr: np.ndarray, max_side: int = 224, q: int = 35) -> str:
    h, w = img_bgr.shape[:2]
    s = max_side / float(max(h, w))
    if s < 1.0:
        img_bgr = cv2.resize(img_bgr, (int(w*s), int(h*s)), interpolation=cv2.INTER_AREA)
    ok, enc = cv2.imencode(".jpg", img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), int(q)])
    return base64.b64encode(enc).decode() if ok else ""

def _gpt_vision(client, sys_prompt: str, user_text: str, img_bgr: Optional[np.ndarray], model: str) -> str:
    content = [{"type":"input_text","text":user_text}]
    if img_bgr is not None:
        content.append({"type":"input_image","image_url":"data:image/jpeg;base64,"+_img_to_b64(img_bgr)})
    try:
        r = client.responses.create(model=model, input=[{"role":"system","content":sys_prompt},{"role":"user","content":content}],
                                    temperature=0.0, max_output_tokens=200)
        return _extract_text(r)
    except Exception as e:
        log.warning("Proxy error: %s", e)
        return ""

def gpt_brand(img, c, m): return _gpt_vision(c, "–û–ø—Ä–µ–¥–µ–ª–∏ –º–∞—Ä–∫—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –º–∞—Ä–∫—É.", "–ö–∞–∫–∞—è –º–∞—Ä–∫–∞ –∞–≤—Ç–æ?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–∞—Ä–∫—É"
def gpt_color(img, c, m): return _gpt_vision(c, "–û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–≤–µ—Ç –∫—É–∑–æ–≤–∞ (–æ–¥–Ω–æ —Å–ª–æ–≤–æ –ø–æ-—Ä—É—Å—Å–∫–∏).", "–ö–∞–∫–æ–π —Ü–≤–µ—Ç –∞–≤—Ç–æ?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ü–≤–µ—Ç"
def gpt_type (img, c, m): return _gpt_vision(c, "–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Ç–∏–ø: –ª–µ–≥–∫–æ–≤–æ–π/–≥—Ä—É–∑–æ–≤–æ–π/–∞–≤—Ç–æ–±—É—Å/–º–æ—Ç–æ—Ü–∏–∫–ª. –í–µ—Ä–Ω–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ.", "–ö–∞–∫–æ–π —Ç–∏–ø –¢–°?", img, m) or "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–∏–ø –∞–≤—Ç–æ–º–æ–±–∏–ª—è"
def gpt_reg_year(plate, c, m):
    if not plate: return "", ""
    sys = ("–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –≥–æ—Å–Ω–æ–º–µ—Ä (–ê123–í–°77/–ê123–í–°777). "
           "–ü–æ –∫–æ–¥—É —Ä–µ–≥–∏–æ–Ω–∞ –Ω–∞–∑–æ–≤–∏ —Å—É–±—ä–µ–∫—Ç –†–§ –∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏ –≥–æ–¥ –≤—ã–¥–∞—á–∏. "
           "–°—Ç—Ä–æ–≥–æ JSON: {\"region_name\":\"...\",\"year_issued\":\"...\"}.")
    txt = _gpt_vision(c, sys, f"–û–ø—Ä–µ–¥–µ–ª–∏ —Ä–µ–≥–∏–æ–Ω+–≥–æ–¥ –≤—ã–¥–∞—á–∏ –¥–ª—è: {plate}", None, m)
    try:
        j = json.loads(txt); return j.get("region_name",""), j.get("year_issued","")
    except Exception:
        return "", ""

def _first_existing(paths: List[Path]) -> Optional[Path]:
    for p in paths:
        if p and Path(p).exists():
            return Path(p)
    return None

def _find_yolo(user: Optional[Path]) -> Optional[Path]:
    return _first_existing([user or Path(), Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/models/YOLOv8.pt"), Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/utils/YOLOv8.pt"), Path("YOLOv8.pt")])

def _find_cascade(user: Optional[Path]) -> Optional[Path]:
    return _first_existing([
        user or Path(),
        Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/haarcascade_licence_plate_rus_16stages.xml"),
        Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/haarcascade_russian_plate_number.xml"),
        Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/models/cascades/haarcascade_licence_plate_rus_16stages.xml"),
        Path("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/models/haarcascade_licence_plate_rus_16stages.xml"),
    ])

@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ CNN‚Ä¶")
def _load_cnn(path: Path):
    if not TF_OK:
        raise RuntimeError("TensorFlow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–º –¥–µ–ø–ª–æ–µ; CNN-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ.")
    return tf.keras.models.load_model(str(path))

@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ YOLO‚Ä¶")
def _load_yolo(path: Path):
    if not _YOLO_OK: return None
    try:
        return YOLO(str(path))
    except Exception as e:
        log.error("YOLO load failed: %s", e)
        return None

def _is_plausible_box(x, y, w, h, H, W) -> bool:
    if w <= 0 or h <= 0: return False
    ar = w / float(h)
    h_frac, w_frac = h/float(H), w/float(W)
    if not (2.2 <= ar <= 6.8): return False
    if not (0.03 <= h_frac <= 0.20): return False
    if not (0.08 <= w_frac <= 0.60): return False
    return True

def _edge_density(gray_roi: np.ndarray) -> float:
    e = cv2.Canny(gray_roi, 70, 160)
    return float(e.mean())/255.0

def _locate_plate_morph(img_bgr: np.ndarray) -> Optional[Tuple[int,int,int,int]]:
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    rect_k = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rect_k)
    grad = cv2.Sobel(blackhat, cv2.CV_32F, 1, 0, ksize=-1)
    grad = np.absolute(grad)
    grad = (255 * (grad - grad.min()) / (grad.ptp() + 1e-6)).astype(np.uint8)
    grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, rect_k, iterations=1)
    _, bw = cv2.threshold(grad, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, rect_k, iterations=2)
    bw = cv2.medianBlur(bw, 3)
    cnts, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    H, W = gray.shape[:2]
    best = None; best_score = -1.0
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if not _is_plausible_box(x,y,w,h,H,W):
            continue
        roi = gray[y:y+h, x:x+w]
        score = 0.6 * _edge_density(roi) + 0.4 * (1.0 - min(1.0, abs((w/h) - 4.5) / 3.5))
        if score > best_score:
            best_score = score; best = (x,y,w,h)
    return best

def plate_detect_haar(img_bgr: np.ndarray, cascade_path: Path) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    cascade = cv2.CascadeClassifier(str(cascade_path))
    if cascade.empty():
        st.warning("–ö–∞—Å–∫–∞–¥ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ *.xml.")
        return img_bgr, None
    rects = cascade.detectMultiScale(gray, scaleFactor=1.08, minNeighbors=4, minSize=(50,16), flags=cv2.CASCADE_SCALE_IMAGE)
    H, W = gray.shape[:2]
    best = None; best_score = -1.0
    for (x,y,w,h) in rects:
        if not _is_plausible_box(x,y,w,h,H,W): continue
        roi = gray[y:y+h, x:x+w]
        score = 0.6 * _edge_density(roi) + 0.4 * (1.0 - min(1.0, abs((w/h) - 4.5) / 3.5))
        if score > best_score:
            best_score = score; best = (x,y,w,h)
    if best is None:
        best = _locate_plate_morph(img_bgr)
        if best is None:
            return img_bgr, None
    x,y,w,h = best
    pad_x, pad_y = int(0.03*w), int(0.12*h)
    x1, y1 = max(0, x-pad_x), max(0, y-pad_y)
    x2, y2 = min(W, x+w+pad_x), min(H, y+h+pad_y)
    roi = img_bgr[y1:y2, x1:x2].copy()
    out = img_bgr.copy()
    cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)
    return out, roi

def plate_detect_yolo(img_bgr: np.ndarray, model) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    res = model.predict(img_bgr, verbose=False, device="cpu", conf=0.25, iou=0.5)
    H, W = img_bgr.shape[:2]
    for r in res:
        names = getattr(r, "names", {}) or {}
        boxes = r.boxes
        if boxes is None or len(boxes) == 0: continue
        xyxy = boxes.xyxy.cpu().numpy().astype(int)
        conf = boxes.conf.cpu().numpy()
        cls  = boxes.cls.cpu().numpy().astype(int)
        cand = [i for i,c in enumerate(cls) if str(names.get(int(c), "")).lower().replace("-","_") in ("license_plate","licenseplate","plate")]
        if not cand:
            ar = (xyxy[:,2]-xyxy[:,0]) / np.maximum(1, (xyxy[:,3]-xyxy[:,1]))
            scores = conf + (np.clip(1.0 - np.abs(ar-4.5)/3.5, 0, 1)*0.5)
            idx = int(np.argmax(scores))
        else:
            idx = int(cand[np.argmax(conf[cand])])
        x1,y1,x2,y2 = xyxy[idx]
        w,h = x2-x1, y2-y1
        if not _is_plausible_box(x1,y1,w,h,H,W):
            best = _locate_plate_morph(img_bgr)
            if best is not None:
                x,y,w,h = best
                x1,y1,x2,y2 = x,y,x+w,y+h
        pad_x, pad_y = int(0.03*(x2-x1)), int(0.12*(y2-y1))
        x1,y1 = max(0,x1-pad_x), max(0,y1-pad_y)
        x2,y2 = min(W,x2+pad_x), min(H,y2+pad_y)
        roi = img_bgr[y1:y2, x1:x2].copy()
        out = img_bgr.copy()
        cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)
        return out, roi
    return img_bgr, None

def plate_detect(img_bgr: np.ndarray, method: str, yolo_path: Optional[Path], cascade_path: Optional[Path]) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    if method == "YOLOv8":
        ypath = _find_yolo(yolo_path)
        if ypath:
            y = _load_yolo(ypath)
            if y is not None:
                out, roi = plate_detect_yolo(img_bgr, y)
                if roi is not None:
                    return out, roi
    cpath = _find_cascade(cascade_path)
    if cpath:
        return plate_detect_haar(img_bgr, cpath)
    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –∫–∞—Å–∫–∞–¥–∞ –¥–ª—è Haar-–¥–µ—Ç–µ–∫—Ü–∏–∏.")
    return img_bgr, None

def _segment_characters_legacy(image: np.ndarray) -> np.ndarray:
    if image is None: return np.array([])
    img_lp = cv2.resize(image, (333, 75))
    img_gray = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)
    img_bin = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)))
    img_bin[0:3, :], img_bin[:, 0:3] = 255, 255
    img_bin[72:75, :], img_bin[:, 330:333] = 255, 255
    LP_W, LP_H = img_bin.shape
    dims = [LP_W / 6, LP_W / 2, LP_H / 10, 2 * LP_H / 3]
    lower_h, upper_h = dims[0] * 0.5, dims[1] * 1.2
    lower_w, upper_w = dims[2] * 0.5, dims[3] * 1.2
    contours, hierarchy = cv2.findContours(img_bin.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if hierarchy is None: return np.array([])
    chars, xs = [], []
    for i, cnt in enumerate(contours):
        if hierarchy[0][i][3] == -1: continue
        x, y, w, h = cv2.boundingRect(cnt)
        ar = w / float(h)
        if lower_h < h < upper_h and lower_w < w < upper_w and 0.3 < ar < 1.2:
            char = cv2.subtract(255, cv2.resize(img_bin[y:y+h, x:x+w], (20, 40)))
            char_copy = np.zeros((44, 24), dtype=np.uint8)
            char_copy[2:42, 2:22] = char
            chars.append(char_copy); xs.append(x)
    if not chars: return np.array([])
    idx_sorted = np.argsort(np.array(xs))
    return np.array([chars[i] for i in idx_sorted])

def _fix_dim(img):
    return np.stack((img,)*3, axis=-1) if img.ndim == 2 else img

def recognize_number_cnn(roi: np.ndarray, model, thr: float) -> Tuple[str, List[float]]:
    seg_chars = _segment_characters_legacy(roi)
    if seg_chars.size == 0: return "", []
    out, confs = [], []
    for ch in seg_chars:
        img28 = cv2.resize(ch, (28, 28))
        X = _fix_dim(img28) / 255.0
        pr = model.predict(X.reshape(1, 28, 28, 3), verbose=0)
        idx = int(np.argmax(pr))
        cf = float(pr[0, idx])
        out.append(_NUM2CHAR[idx] if cf >= thr else "?")
        confs.append(cf)
    return "".join(out), confs

def fix_number_format_new_rus(s: str, confs: List[float]) -> Tuple[str, List[float]]:
    pat = r"^([–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•])\d{3}[–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•]{2}\d{2,3}$"
    if re.match(pat, s or ""): return s, confs
    if s and s[-1] in _CHARS:
        cand = s[:-1]
        if re.match(pat, cand or ""): return cand, confs[:-1]
    return s or "", confs

def render_plate_assistant(db_path: Path):
    st.header("ü™™ –ù–æ–º–µ—Ä + –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç")
    if not CV2_OK:
        st.warning("OpenCV (cv2) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –í–∫–ª–∞–¥–∫–∞ ¬´–ù–æ–º–µ—Ä + –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç¬ª –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–µ—Ç–∞–ª—å –æ—à–∏–±–∫–∏"):
            st.code(repr(CV2_ERR))
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ requirements.txt –Ω–µ—Ç opencv-python, –∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω opencv-python-headless.")
        return
        
    defaults = get_defaults()
    with st.sidebar:
        st.subheader("ProxyAPI")
        api_key = st.text_input("API key", value=defaults["api_key"], type="password")
        base_url = st.text_input("Base URL", value=defaults["base_url"])
        gpt_model = st.selectbox("–ú–æ–¥–µ–ª—å", ["gpt-4o-mini","gpt-4o","gpt-4o-mini-compact"], index=0)

        st.subheader("–ú–æ–¥–µ–ª–∏")
        yolo_path_ui = st.text_input("YOLOv8 –≤–µ—Å–∞ (–∏—â–µ–º —Ç–∞–∫–∂–µ utils/YOLOv8.pt)", value="models/YOLOv8.pt")
        cascade_path_ui = st.text_input("Haar Cascade (–∞–≤—Ç–æ–ø–æ–∏—Å–∫)", value="haarcascade_licence_plate_rus_16stages.xml")
        cnn_path = st.text_input("CNN (model.h5)", value="model.h5")

        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
        fmt = st.selectbox("–§–æ—Ä–º–∞—Ç –Ω–æ–º–µ—Ä–∞", ['–°—Ç–∞—Ä—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ó–∞—Ä—É–±–µ–∂–Ω—ã–µ –Ω–æ–º–µ—Ä–∞'], index=1)
        det_m = st.selectbox("–ú–µ—Ç–æ–¥ –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–æ–º–µ—Ä–∞", ['YOLOv8','Haar Cascade (legacy)'],
                             index=0 if (_find_yolo(Path(yolo_path_ui)) is not None and _YOLO_OK) else 1)
        thr = st.slider("–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (CNN), –Ω–∏–∂–µ ‚Äî '?'", 0.0, 1.0, 0.50, 0.05)

    c1,c2 = st.columns([1,1])
    with c1: f = st.file_uploader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è", type=["jpg","jpeg","png"])
    with c2:
        do_all = st.checkbox("–í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å—ë (–º–∞—Ä–∫–∞/—Ç–∏–ø/—Ü–≤–µ—Ç/—Ä–µ–≥–∏–æ–Ω)", value=True)
        btn = st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", type="primary", use_container_width=True)

    if f:
        pil = Image.open(f)
        w = 420
        st.image(pil.resize((w, int(pil.height*(w/pil.width))), Image.Resampling.LANCZOS),
                 caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—É–º–µ–Ω—å—à–µ–Ω–æ)", width=420)

    if not btn or not f:
        return

    client = get_client(api_key=api_key, base_url=base_url)
    img_bgr = np.array(Image.open(f).convert("RGB"))[:, :, ::-1]

    # 1) –î–µ—Ç–µ–∫—Ü–∏—è
    det_img, roi = plate_detect(img_bgr, det_m, Path(yolo_path_ui), Path(cascade_path_ui))
    if roi is None:
        best = _locate_plate_morph(img_bgr)
        if best is not None:
            x,y,w,h = best
            pad_x, pad_y = int(0.03*w), int(0.12*h)
            x1,y1 = max(0, x - pad_x), max(0, y - pad_y)
            x2,y2 = min(img_bgr.shape[1], x+w+pad_x), min(img_bgr.shape[0], y+h+pad_y)
            roi = img_bgr[y1:y2, x1:x2].copy()
            det_img = img_bgr.copy()
            cv2.rectangle(det_img, (x1,y1), (x2,y2), (0,255,0), 2)

    st.subheader("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞‚Ä¶")
    st.image(cv2.cvtColor(det_img, cv2.COLOR_BGR2RGB), caption="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–æ–º–µ—Ä", width=360)

    # 2) CNN (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    plate, confs = "", []
    if TF_OK:
        try:
            cnn = _load_cnn(Path(cnn_path))
            plate, confs = recognize_number_cnn(roi, cnn, thr)
            if fmt == '–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞' and plate:
                plate, confs = fix_number_format_new_rus(plate, confs)
        except Exception as e:
            st.info(f"CNN –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    else:
        st.info("TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (Py3.13 Cloud). CNN-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –æ—Ç–∫–ª—é—á–µ–Ω–æ.")

    # 3) GPT
    brand = color = car_type = ""
    if do_all:
        brand = gpt_brand(img_bgr, client, gpt_model)
        color = gpt_color(img_bgr, client, gpt_model)
        car_type = gpt_type(img_bgr, client, gpt_model)
    region, year = ("","")
    if plate and fmt in ('–°—Ç–∞—Ä—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞','–ù–æ–≤—ã–µ –†–§ –Ω–æ–º–µ—Ä–∞'):
        st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–º–µ—Ä–∞ (—Ä–µ–≥–∏–æ–Ω, –≥–æ–¥ –≤—ã–¥–∞—á–∏)‚Ä¶")
        region, year = gpt_reg_year(plate, client, gpt_model)

    # 4) –í—ã–≤–æ–¥
    st.success("–ì–æ—Ç–æ–≤–æ.")
    st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    st.write(f"**–ù–æ–º–µ—Ä**: {plate or '‚Äî'}")
    if region: st.write(f"**–†–µ–≥–∏–æ–Ω**: {region}")
    if year:   st.write(f"**–ì–æ–¥ –≤—ã–¥–∞—á–∏**: {year}")
    if confs:
        avg = float(sum(confs)/len(confs))
        st.write(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (CNN): {avg:.2f}")
        if plate and len(plate) == len(confs):
            df = pd.DataFrame({"–°–∏–º–≤–æ–ª": list(plate), "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": confs})
            st.bar_chart(df, x="–°–∏–º–≤–æ–ª", y="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
    if brand:    st.write(f"**–ú–∞—Ä–∫–∞**: {brand}")
    if car_type: st.write(f"**–¢–∏–ø**: {car_type}")
    if color:    st.write(f"**–¶–≤–µ—Ç**: {color}")

    # 5) –ë–î
    avg_conf = float(sum(confs)/len(confs)) if confs else None
    insert_detection(
        db_path=db_path,
        ts=time.strftime("%Y-%m-%dT%H:%M:%S"),
        kind="plate", source="image", filename=f.name,
        model=("YOLOv8‚Üí" if det_m=="YOLOv8" else "") + "Haar/Morph" + ("+CNN" if confs else ""),
        label_en=plate or None, label_ru=plate or None, score=avg_conf,
        json_top5=None, price_min=None, price_max=None, currency=None, image_path=None,
        plate_number=plate or None, region=region or None, year_issued=year or None,
        brand=brand or None, car_type=car_type or None, color=color or None, conf_avg=avg_conf, extra_json=None
    )
    st.toast("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ detections.db", icon="üíæ")


