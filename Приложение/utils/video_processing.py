"""
utils/video_processing.py
=========================
‚Ä¢ process_uploaded_video  ‚Äì –æ—Ñ—Ñ-–ª–∞–π–Ω: —Ñ–∞–π–ª ‚Üí —Ñ–∞–π–ª
‚Ä¢ process_video_realtime  ‚Äì ‚ö° –∫–∞–¥—Ä-–∑–∞-–∫–∞–¥—Ä–æ–º –¥–ª—è Streamlit
‚Ä¢ process_rtsp_stream     ‚Äì live-–∫–∞–º–µ—Ä–∞ / RTSP
"""

from __future__ import annotations
import cv2
import os
import tempfile
import logging
import time
from typing import Dict, Iterator, Tuple, Optional

from utils.image_processing import draw_boxes
from utils.database import log_detections_bulk
from utils.chat_comment import summarize_detections

logger = logging.getLogger(__name__)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def process_uploaded_video(
    video_path: str,
    model,
    conf_thresh: float,
    line_thickness: int,
    db_session,
) -> str:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ—Ñ–∞–π–ª, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π .mp4 –∏
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –Ω–µ–º—É.
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError(video_path)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    fd, out_path = tempfile.mkstemp(suffix=".mp4")
    os.close(fd)
    writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    while True:
        ok, frame = cap.read()
        if not ok:
            break
        detections = model.predict(frame, conf=conf_thresh)
        frame = draw_boxes(frame, detections, conf_thresh, model, line_thickness)
        writer.write(frame)

    cap.release()
    writer.release()
    logger.info("–í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: %s ‚Üí %s", video_path, out_path)
    return out_path


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def process_video_realtime(
    video_path: str,
    model,
    conf_thresh: float,
    line_thickness: int,
    db_session,
    gpt_every: int = 60,
) -> Iterator[Tuple]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä: –¥–∞—ë—Ç (BGR-–∫–∞–¥—Ä, Optional[str-gptComment]) –∫–∞–∂–¥—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–æ –≤–∫–ª–∞–¥–∫–µ ¬´‚ö° –í–∏–¥–µ–æ-—Ñ–∞–π–ª online¬ª.
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")

    frame_idx: int = 0
    counts: Dict[str, int] = {}

    while True:
        ok, frame = cap.read()
        if not ok:
            break

        detections = model.predict(frame, conf=conf_thresh)
        frame = draw_boxes(frame, detections, conf_thresh, model, line_thickness)

        # tally
        for det in detections:
            cls_id = int(det[5])
            name = model.model.names[cls_id]
            counts[name] = counts.get(name, 0) + 1

        # –ø–∏—à–µ–º –≤ –ë–î —Ä–∞–∑ –≤ 30 –∫–∞–¥—Ä–æ–≤
        if frame_idx % 30 == 0:
            try:
                log_detections_bulk(db_session, detections)
            except Exception:
                pass

        gpt_comment: Optional[str] = None
        if frame_idx and frame_idx % gpt_every == 0:
            gpt_comment = summarize_detections(counts)
            counts = {}

        frame_idx += 1
        yield frame, gpt_comment

    cap.release()


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def process_rtsp_stream(
    rtsp_url: str,
    model,
    conf_thresh: float,
    line_thickness: int,
    db_session,
) -> None:
    """
    Live-–ø–æ—Ç–æ–∫ RTSP / IP-–∫–∞–º–µ—Ä–∞. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–¥—Ä—ã –≤ Streamlit.
    """
    import streamlit as st

    cap = cv2.VideoCapture(rtsp_url)
    if not cap.isOpened():
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ RTSP: {rtsp_url}")

    st_frame = st.empty()
    st_comment = st.empty()
    frame_idx: int = 0
    counts: Dict[str, int] = {}

    while True:
        ok, frame = cap.read()
        if not ok:
            break

        detections = model.predict(frame, conf=conf_thresh)
        frame = draw_boxes(frame, detections, conf_thresh, model, line_thickness)

        # —Å—á—ë—Ç
        for det in detections:
            cls_id = int(det[5])
            name = model.model.names[cls_id]
            counts[name] = counts.get(name, 0) + 1

        # –≤—ã–≤–æ–¥ –∫–∞–¥—Ä–∞
        st_frame.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),
                       channels="RGB", use_column_width=True)

        # GPT-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫–∞–∂–¥—ã–µ 60 –∫–∞–¥—Ä–æ–≤
        if frame_idx and frame_idx % 60 == 0:
            st_comment.markdown(
                f"**üí¨ GPT:** {summarize_detections(counts)}")
            counts = {}

        # –ë–î
        if frame_idx % 30 == 0:
            try:
                log_detections_bulk(db_session, detections)
            except Exception:
                pass

        frame_idx += 1

    cap.release()
